{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1774d68-d42c-43d1-926f-b6d65dcfad8b",
   "metadata": {},
   "source": [
    "# RAG (Langchain and Mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55754120-8609-4642-8ac1-ba0018148501",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8c3082-6a31-4b86-ae01-a68d095b0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461b7667-ba34-43b2-b78f-c3563afb3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "os.environ['MISTRAL_API_KEY'] = \"Uaj41DARGjquAh7l2HGuwVef2LAsVfeb\"\n",
    "mistral_api_key = \"Uaj41DARGjquAh7l2HGuwVef2LAsVfeb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea242b86-2517-4bb6-b053-09484bce6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = \"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\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935dfd61-e9c1-43ee-b812-f47969affe84",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "302be809-a04f-4029-abe6-9562712efa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1c82cbf-520c-401a-bbc6-1b55bd2394d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1346, which is longer than the specified 1000\n",
      "Created a chunk of size 2446, which is longer than the specified 1000\n",
      "Created a chunk of size 4437, which is longer than the specified 1000\n",
      "Created a chunk of size 1633, which is longer than the specified 1000\n",
      "Created a chunk of size 4349, which is longer than the specified 1000\n",
      "Created a chunk of size 4030, which is longer than the specified 1000\n",
      "Created a chunk of size 1538, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "cohere_key = \"8acOGXby2VEQ70UErIkns9I0qGLUu9QT6KIYfzpA\"\n",
    "\n",
    "embeddings_model = CohereEmbeddings(cohere_api_key = cohere_key)\n",
    "loader = CSVLoader(file_path=\"/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv\")\n",
    "data = loader.load()\n",
    "data_test = data[:10]\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_csv = text_splitter.split_documents(data_test)\n",
    "vectorstore = Chroma.from_documents(documents=split_csv, \n",
    "                                    embedding=embeddings_model)\n",
    "\n",
    "#retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6881228-ee60-42fb-b94f-ad3f294ff39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-sebastiengaultier/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:379: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='Unnamed: 0: 0\\ndescription: A 23-year-old white female presents with complaint of allergies.\\nmedical_specialty: Allergy / Immunology\\nsample_name: Allergic Rhinitis', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6012.5468074951), (Document(page_content='Unnamed: 0: 0\\ndescription: A 23-year-old white female presents with complaint of allergies.\\nmedical_specialty: Allergy / Immunology\\nsample_name: Allergic Rhinitis', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6012.5468074951), (Document(page_content='transcription: SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6080.139034223288), (Document(page_content='transcription: SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6080.139034223288)]\n",
      "  warnings.warn(\n",
      "/Users/jean-sebastiengaultier/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:391: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.1\n",
      "  warnings.warn(\n",
      "/Users/jean-sebastiengaultier/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:379: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='Unnamed: 0: 0\\ndescription: A 23-year-old white female presents with complaint of allergies.\\nmedical_specialty: Allergy / Immunology\\nsample_name: Allergic Rhinitis', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6012.5468074951), (Document(page_content='Unnamed: 0: 0\\ndescription: A 23-year-old white female presents with complaint of allergies.\\nmedical_specialty: Allergy / Immunology\\nsample_name: Allergic Rhinitis', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6012.5468074951), (Document(page_content='transcription: SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6080.139034223288), (Document(page_content='transcription: SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.', metadata={'row': 0, 'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/mtsamples_with_rand_names.csv'}), -6080.139034223288)]\n",
      "  warnings.warn(\n",
      "/Users/jean-sebastiengaultier/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:391: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the retrieved context, it is unclear how many people have allergies. However, it is estimated that around 30% of the global population suffers from some form of allergic disease. Allergies are quite common, affecting people of all ages and backgrounds."
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.1})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"How many people have allergies?\")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatCohere(model=\"command-r\", cohere_api_key = cohere_key)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"How many people have allergies?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bde332fe-aecb-408d-86ff-a17a46b5cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least two people have allergies. A 23-year-old female suffers from allergic rhinitis, and a 42-year-old male is allergic to penicillin."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2fba30-0c7b-4bdb-8fd3-4a7cc81a19ce",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76dd3b87-a621-4c66-baba-fb8cd2b2ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/data_test\"\n",
    "\n",
    "# Load data using Markdown Document Loader\n",
    "def load_markdown_documents(directory):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.md'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "            documents.append(loader.load())\n",
    "    return documents\n",
    "\n",
    "documents = load_markdown_documents(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89414fc1-e110-49ee-9152-7b087c2f174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split them into chunks\n",
    "def split_documents_by_paragraph(documents):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    split = []\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_documents(doc)\n",
    "        split.extend(chunks)  # Flatten the list of lists\n",
    "    return split\n",
    "\n",
    "split = split_documents_by_paragraph(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa72e7be-6aa4-4cfb-80ee-5115139ede92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred with MistralAI: 'data'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     vectorstore\u001b[38;5;241m.\u001b[39madd_documents(split_docs)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n\u001b[0;32m----> 7\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m create_embeddings_and_store(split, mistral_api_key)\n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36mcreate_embeddings_and_store\u001b[0;34m(split_docs, mistral_api_key)\u001b[0m\n\u001b[1;32m      2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m MistralAIEmbeddings(api_key\u001b[38;5;241m=\u001b[39mmistral_api_key)\n\u001b[1;32m      3\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma(embedding_function\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[0;32m----> 4\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39madd_documents(split_docs)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:147\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    146\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_texts(texts, metadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:276\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:158\u001b[0m, in \u001b[0;36mMistralAIEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    150\u001b[0m             url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batches(texts)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, embedding_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m batch_responses\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m embedding_obj \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    162\u001b[0m     ]\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    164\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred with MistralAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    150\u001b[0m             url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batches(texts)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, embedding_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m batch_responses\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m embedding_obj \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    162\u001b[0m     ]\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    164\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred with MistralAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "def create_embeddings_and_store(split_docs, mistral_api_key):\n",
    "    embeddings = MistralAIEmbeddings(api_key=mistral_api_key)\n",
    "    vectorstore = Chroma(embedding_function=embeddings)\n",
    "    vectorstore.add_documents(split_docs)\n",
    "    return vectorstore\n",
    "\n",
    "vectorstore = create_embeddings_and_store(split, mistral_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1744acc-4db0-4fc8-8ced-261afa14d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-sebastiengaultier/anaconda3/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:105: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = MistralAIEmbeddings(api_key=mistral_api_key)\n",
    "vectorstore = Chroma(\"langchain_store\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a124b1-90f8-413c-ac2b-b19e1857ddb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0bc171ba-cfdb-4a3e-b681-64e743606356',\n",
       " 'fa5f5df1-b004-4809-88de-72be27c6fd47']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7642254d-d137-421e-8bff-21bf8c851de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['420d91d6-8467-40cc-8621-5f146ee0b290',\n",
       " 'e526e493-d4e8-4c13-8aa3-2ed14029ebaf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a916ddd2-b5c1-49ec-bd7d-72ed74e355af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['64ab3b7d-af67-48c3-8edf-47194192a537',\n",
       " 'fc59d596-ac84-4339-91b4-e8c902ed3aca']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3651f7b3-643e-41dd-a02e-0e0e49ca2e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Patient Data: 4\\n\\nName: Eugene Hewitt\\n\\nSample Name:  2-D Echocardiogram - 2\\n\\nMedical Field:  Cardiovascular / Pulmonary\\n\\nDescription:  2-D Echocardiogram\\n\\nKeywords: cardiovascular / pulmonary, 2-d, doppler, echocardiogram, annular, aortic root, aortic valve, atrial, atrium, calcification, cavity, ejection fraction, mitral, obliteration, outflow, regurgitation, relaxation pattern, stenosis, systolic function, tricuspid, valve, ventricular, ventricular cavity, wall motion, pulmonary artery', metadata={'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/data_test/4.md'}),\n",
       " Document(page_content='Transcription: 1.  The left ventricular cavity size and wall thickness appear normal.  The wall motion and left ventricular systolic function appears hyperdynamic with estimated ejection fraction of 70% to 75%.  There is near-cavity obliteration seen.  There also appears to be increased left ventricular outflow tract gradient at the mid cavity level consistent with hyperdynamic left ventricular systolic function.  There is abnormal left ventricular relaxation pattern seen as well as elevated left atrial pressures seen by Doppler examination.,2.  The left atrium appears mildly dilated.,3.  The right atrium and right ventricle appear normal.,4.  The aortic root appears normal.,5.  The aortic valve appears calcified with mild aortic valve stenosis, calculated aortic valve area is 1.3 cm square with a maximum instantaneous gradient of 34 and a mean gradient of 19 mm.,6.  There is mitral annular calcification extending to leaflets and supportive structures with thickening of mitral valve leaflets with mild mitral regurgitation.,7.  The tricuspid valve appears normal with trace tricuspid regurgitation with moderate pulmonary artery hypertension.  Estimated pulmonary artery systolic pressure is 49 mmHg.  Estimated right atrial pressure of 10 mmHg.,8.  The pulmonary valve appears normal with trace pulmonary insufficiency.,9.  There is no pericardial effusion or intracardiac mass seen.,10.  There is a color Doppler suggestive of a patent foramen ovale with lipomatous hypertrophy of the interatrial septum.,11.  The study was somewhat technically limited and hence subtle abnormalities could be missed from the study.,', metadata={'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/data_test/4.md'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bb14d2-351b-4fcd-af0c-ad5a1afd66eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred with MistralAI: 'data'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39madd_documents(split[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/vectorstores.py:147\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    146\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_texts(texts, metadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:276\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:158\u001b[0m, in \u001b[0;36mMistralAIEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    150\u001b[0m             url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batches(texts)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, embedding_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m batch_responses\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m embedding_obj \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    162\u001b[0m     ]\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    164\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred with MistralAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_mistralai/embeddings.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     batch_responses \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    150\u001b[0m             url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batches(texts)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, embedding_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m batch_responses\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m embedding_obj \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    162\u001b[0m     ]\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    164\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred with MistralAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "vectorstore.add_documents(split[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "922d57f2-df10-4b1d-b352-4fb9cf159825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a890c275-930e-4458-b305-c94ff76cb5f7',\n",
       " 'ba432d36-2690-46a9-9b6c-e860bd5100ac']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(split[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29116e50-b17d-46aa-b186-ecadb213150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33159831-ed1d-4858-bcac-e654b4660be8']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.add_documents(split[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9069d8f3-16a4-4afb-a350-eb2442c6d5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Patient Data: 9\\n\\nName: Johnnie Davis\\n\\nSample Name:  2-D Echocardiogram - 4\\n\\nMedical Field:  Cardiovascular / Pulmonary\\n\\nDescription:  Echocardiogram and Doppler\\n\\nKeywords: cardiovascular / pulmonary, ejection fraction, lv systolic function, cardiac chambers, regurgitation, tricuspid, normal lv systolic function, normal lv systolic, ejection fraction estimated, normal lv, lv systolic, systolic function, function ejection, echocardiogram, doppler, lv, systolic, ejection, mitral, valve\\n\\nTranscription: DESCRIPTION:,1.  Normal cardiac chambers size.,2.  Normal left ventricular size.,3.  Normal LV systolic function.  Ejection fraction estimated around 60%.,4.  Aortic valve seen with good motion.,5.  Mitral valve seen with good motion.,6.  Tricuspid valve seen with good motion.,7.  No pericardial effusion or intracardiac masses.,DOPPLER:,1.  Trace mitral regurgitation.,2.  Trace tricuspid regurgitation.,IMPRESSION:,1.  Normal LV systolic function.,2.  Ejection fraction estimated around 60%.,', metadata={'source': '/Users/jean-sebastiengaultier/Desktop/UChicago/Academic/Hackathon/data_test/9.md'})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c9b6d96-7b8d-41d1-ae8b-5f70c17f351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'MistralAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1747854d0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adb02f-f455-4bc9-83ae-fcdc40c35abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
